#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{url} 
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman times
\font_sans helvet
\font_typewriter courier
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 0
\use_mhchem 0
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
World Models
\end_layout

\begin_layout Date
Draft Version 0.01 - 13 Sept 2016
\end_layout

\begin_layout Abstract
A description of how OpenCog currently implements self-awareness and world-aware
ness, together with a sketch of how this could be improved and expanded.
 The short-term goal is to create a robot (embodied chatbot) that can hear
 and see, and carry on conversations about perceived objects, as well as
 to carry out conversations about the self.
 These conversations can be verbal, and can also have physical-body performance
 components: body and face expressive movements, such as smiling or waving
 a hand.
 
\end_layout

\begin_layout Section*
Overview
\end_layout

\begin_layout Standard
The basic premise that will be elaborated here is that interacting with
 the world requires the creation of an 
\begin_inset CommandInset href
LatexCommand href
name "internal model"
target "https://en.wikipedia.org/wiki/Internal_model_(motor_control)"

\end_inset

 of the world: in systems theory, this is sometimes called 
\begin_inset Quotes eld
\end_inset

the 
\begin_inset CommandInset href
LatexCommand href
name "good regulator theorem"
target "https://en.wikipedia.org/wiki/Good_regulator"

\end_inset

.
\begin_inset Quotes erd
\end_inset

 An internal model provides the system software with a natural API, a natural
 representation, that various different software components can agree on,
 and use, and manipulate, and reason with.
 
\end_layout

\begin_layout Subsubsection*
AtomSpace
\end_layout

\begin_layout Standard
To acheive a unification of speech, behavior and perception, one must have
 a software infrastructure that allows these to be represented in a unified
 way: that is, the data and algorithms must reside in some unified location.
 From here on out, it is assumed that this unified location is the 
\begin_inset CommandInset href
LatexCommand href
name "OpenCog AtomSpace"
target "http://wiki.opencog.org/w/AtomSpace"

\end_inset

.
 This is stated explicitly, because, in the course of discussion, various
 other technology platforms have been nominated.
 Although one could debate the merits of alternative technologies, this
 will not be done here.
\end_layout

\begin_layout Subsubsection*
Self Model
\end_layout

\begin_layout Standard
The self-model, and together with it, the controversial term 
\begin_inset Quotes eld
\end_inset

self-awareness
\begin_inset Quotes erd
\end_inset

, is here defined to simply be an internal model of the robot itself: both
 of low-level physical variables, such as motor angles, as well as higher-order
 concepts such as 
\begin_inset Quotes eld
\end_inset

I smiled just a few seconds ago
\begin_inset Quotes erd
\end_inset

, or 
\begin_inset Quotes eld
\end_inset

I just said this-and-such
\begin_inset Quotes erd
\end_inset

.
 A basic assumption taken in the following is that the engineering and design
 of the self-model is not any different than the engineering and design
 of the world-model: the data types and access methods are the same for
 both.
 Thus, ideas like 
\begin_inset Quotes eld
\end_inset

I know that my arm is raised
\begin_inset Quotes erd
\end_inset

 are represented in much the same way as 
\begin_inset Quotes eld
\end_inset

I know that there is a box in the corner of the room.
\begin_inset Quotes erd
\end_inset

 Thus, in what follows, the expression 
\begin_inset Quotes eld
\end_inset

internal model
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

model
\begin_inset Quotes erd
\end_inset

 will refer to both the self-model and the world model, there being no particula
r difference.
\end_layout

\begin_layout Subsubsection*
State
\end_layout

\begin_layout Standard
The model is meant to implemented as 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "program state"
target "https://en.wikipedia.org/wiki/State_(computer_science)"

\end_inset


\begin_inset Quotes erd
\end_inset

.
 In the context of OpenCog, this means that state is represented as set
 of 
\begin_inset CommandInset href
LatexCommand href
name "Atoms"
target "http://wiki.opencog.org/w/Atom"

\end_inset

 in the AtomSpace: the AtomSpace is, by definition, a container designed
 specifically for the purpose of holding and storing Atoms.
 Much of this state is to be represented with the 
\begin_inset CommandInset href
LatexCommand href
name "StateLink"
target "http://wiki.opencog.org/w/StateLink"

\end_inset

, and much of the rest with 
\begin_inset CommandInset href
LatexCommand href
name "EvaluationLinks"
target "http://wiki.opencog.org/w/EvaluationLink"

\end_inset

 and 
\begin_inset CommandInset href
LatexCommand href
name "PredicateNodes"
target "http://wiki.opencog.org/w/PredicateNode"

\end_inset

.
 The precise details follow what is currently the standard best-practices
 in OpenCog.
 That is, there is no particular proposal here to change how things are
 already handled and coded in OpenCog, although a goal here is to clarify
 numerous issues.
\end_layout

\begin_layout Standard
It is critically important that state be represented as Atoms, as, otherwise,
 there is no other practical way of providing access to that state by all
 of the various subsystems that need to examine and manipulate that state.
 This is an absolutely key insight that often seems to be lost: if the state
 data is placed in some C++ or Python or Scheme or Haskel class, it is essential
ly 
\begin_inset Quotes eld
\end_inset

invisible
\begin_inset Quotes erd
\end_inset

 to the very system that needs to work with it.
 This applies to any kind of state: it could be chat state (words and sentences)
 or visual state (pixels, 3D coordinate locations): if it is not represented
 as Atoms, then the myriad learning and reasoning algorithms cannot effectively
 act on this state.
 This is an absolutely key point, and is one reason why non-AtomSpace infrastruc
tures are not being considered: they lack the representational uniformity
 and infrastructure needed for implementing learning and reasoning.
\end_layout

\begin_layout Standard
However, the AtomSpace does have certain peculiar performance characteristics
 and limitations that make it not suitable for all data: for example, one
 would never want to put raw video or audio into it.
 Yet, one does need access to such data, and so specific subsystems can
 be created to efficiently handle special-purpose data.
 A primary example of this is the 
\begin_inset CommandInset href
LatexCommand href
name "SpaceTime"
target "http://wiki.opencog.org/w/SpaceServer"

\end_inset

 subsystem, which represents the 3D locations of objects in an 
\begin_inset CommandInset href
LatexCommand href
name "OctTree"
target "https://en.wikipedia.org/wiki/Octree"

\end_inset

 format, as well as offering a time component.
 Although the SpaceTime subsystem can store data in a compact internal format,
 it is not, however, exempt from having to work with Atoms: data must be
 accessible as Atoms, and suitable query API's must be provided.
 In this example: it is possible to query for nearby time-like events, or
 to answer questions about whether one object is nearer or farther, or maybe
 bigger or smaller, than another.
\end_layout

\begin_layout Subsubsection*
Model and Control
\end_layout

\begin_layout Standard
It is not sufficient to create an internal model of the world, and represent
 it as state: a control API or control language to manipulate that state
 must also be provided.
 The control is the active snippet of code that performs the actions needed
 to update the internal model.
 It can be thought of as the 
\begin_inset Quotes eld
\end_inset

control
\begin_inset Quotes erd
\end_inset

 aspect of the 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "model-view-controller"
target "https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller"

\end_inset


\begin_inset Quotes erd
\end_inset

 (MVC) paradigm from GUI programming.
 There are both engineering and philosophical reasons for having a control
 API.
 The engineering reasons include things like code-reuse, error-checking,
 encapsulation and ease-of-use.
 The philosophical reason is that a control API provides a shim between
 the world of static data, and the world of action and movement.
 That is, as events occur in time, and as the world is in flux, so must
 also be the internal model.
 
\end_layout

\begin_layout Standard
It is useful to think of the control API as a collections of 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 that can be applied to 
\begin_inset Quotes eld
\end_inset

objects
\begin_inset Quotes erd
\end_inset

 (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Model-and-Control"

\end_inset

).
 In object-oriented programming, these 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 are usually called 
\begin_inset Quotes eld
\end_inset

methods
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

messages
\begin_inset Quotes erd
\end_inset

.
 In what follows, these will often be called 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

, or possibly 
\begin_inset Quotes eld
\end_inset

meta-verbs
\begin_inset Quotes erd
\end_inset

 (XXX TODO: we need a good name for this).
 There is an important reason for this choice of terminology.
 First, due to the nature of how data is represented in the AtomSpace, it
 is the case that some given action can be applied to a large swath of the
 data.
 That is, most actions are NOT tightly coupled to the data they are manipulating
, but are quite general.
 This means that the object-oriented paradigm does not work well with our
 concept of 
\begin_inset Quotes eld
\end_inset

internal model
\begin_inset Quotes erd
\end_inset

: its not like there are many different kinds of objects, and they all need
 to have methods.
 More accurately, there are only a few kinds, and many (most?) actions are
 in principle (defacto?) capable of manipulating many (most?) kinds of state.
 The OO paradigm does not provide a good way of thinking about what goes
 on in the atomspace.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Model and Control
\begin_inset CommandInset label
LatexCommand label
name "fig:Model-and-Control"

\end_inset


\end_layout

\end_inset


\begin_inset Graphics
	filename MVC.eps
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
The control API alters the model.
 It does so by applying 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 to the model state.
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "100col%"
height "1pt"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another handy reason for why these 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 can be called 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 is that they are really 
\begin_inset Quotes eld
\end_inset

potential actions
\begin_inset Quotes erd
\end_inset

: nothing happens until they are performed.
 However, they can still be talked about, and reasoned about, and even learned:
 that is, the actions themselves can also be represented with Atoms, thus
 allowing the reasoning subsystem to make inferences such as 
\begin_inset Quotes eld
\end_inset

if I do X, then Y will happen
\begin_inset Quotes erd
\end_inset

 e.g.
 
\begin_inset Quotes eld
\end_inset

if I stick out my tongue, people will laugh, or maybe they will get offended
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
In the same way that it was argued that model state must be represented
 in terms of OpenCog Atoms, or 
\begin_inset Quotes eld
\end_inset

atomese
\begin_inset Quotes erd
\end_inset

, so too must be the verbs.
 That is, the 
\begin_inset Quotes eld
\end_inset

control API
\begin_inset Quotes erd
\end_inset

 is not some C++ code (or python or scheme or haskel...) but rather, it is
 also a collection of Atoms.
 Again, the reson for this is to allow the system to automatically generate
 new verbs, by means of learning, as well as to reason about the results
 of actions.
 Another key idea is that this allows actions to be combined and composed,
 in sequential or parallel order, with different timing.
 That is, the actions are primitives that can be composd into performances,
 that play out over time.
 Representing these as atomese how such composition and performance-scripting
 can be acheived.
\end_layout

\begin_layout Subsubsection*
Control language
\end_layout

\begin_layout Standard
Following the idea of needing to script actions to control behaviors leads
 one naturally to the need for concepts such as modifiers, which come in
 various forms, including 
\begin_inset Quotes eld
\end_inset

adjectives
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

adverbs
\begin_inset Quotes erd
\end_inset

.
 So for example, if 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 corresponds to the atomese describing a robot arm, and 
\begin_inset Quotes eld
\end_inset

raise
\begin_inset Quotes erd
\end_inset

 is an action that can be applied to 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 (that is, the atomese for performing that action), then it is plausible
 to want to say 
\begin_inset Quotes eld
\end_inset

raise the left arm quickly
\begin_inset Quotes erd
\end_inset

.
 Here, 
\begin_inset Quotes eld
\end_inset

quickly
\begin_inset Quotes erd
\end_inset

 is the atomese needed for modulating the rate at which the motors controlling
 the arm are run.
 Likewise, 
\begin_inset Quotes eld
\end_inset

left
\begin_inset Quotes erd
\end_inset

 is the atomese specifier indicating which collection of motors are to be
 controlled.
\end_layout

\begin_layout Standard
Thus, the concept of a 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

 arises naturally within the system.
 Tghe control langauge is NOT English! Although it does have a grammar,
 the grammar is NOT that of English.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Control Language
\begin_inset CommandInset label
LatexCommand label
name "fig:Control-Language"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename language.eps
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
The control language can have a non-trivial grammar associated with it;
 for example, one can 
\begin_inset Quotes eld
\end_inset

turn to the left
\begin_inset Quotes erd
\end_inset

, but one cannot 
\begin_inset Quotes eld
\end_inset

turn to the eyeblink
\begin_inset Quotes erd
\end_inset

 -- they eye-blink animation not being valid with the turn directive.
 The language can control different systems: the physical body or 
\begin_inset Quotes eld
\end_inset

plant
\begin_inset Quotes erd
\end_inset

, the internal model (or self-model, in this case), as well as models representi
ng hypothetical future behavior, or even models that represent memories
 of the past.
 This is possible because the plant and models all use the same representation
 scheme, and thus, the language can act on each equally well.
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "100col%"
height "1pt"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The need for a control language seems to be unavoidable: it is important
 to be able to specify motor speeds, etc.
 Now, if one had an object-oriented system, then one would have a 
\begin_inset Quotes eld
\end_inset

motor
\begin_inset Quotes erd
\end_inset

 object (or an 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 object composed of 
\begin_inset Quotes eld
\end_inset

motor
\begin_inset Quotes erd
\end_inset

 objects), which had a 
\begin_inset Quotes eld
\end_inset

slot
\begin_inset Quotes erd
\end_inset

 (or 
\begin_inset Quotes eld
\end_inset

method
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

message
\begin_inset Quotes erd
\end_inset

) called 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

, and to control the arm, one would send the 
\begin_inset Quotes eld
\end_inset

fast
\begin_inset Quotes erd
\end_inset

 message to the 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

 slot (or 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

 method) on the 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 instance.
 There's nothing particularly wrong with this view, except for the following
 points.
 If the OO language was C++, then the classes and methods must be known
 at compile time: new classes, methods and messages cannot be dynamically
 created, at run-time.
 If the OO language was Javascript, then many of these issues go away: Javascrip
t does allow new methods to be added, at run-time, to pre-existing objects.
 Indeed, in many ways, OpenCog Atomese resembles JavaScript.
 In particular, the Javascipt members are very similiar to OpenCog Atoms,
 in that, at run-time, new members and methods can be added to objects.
 One could also say that OpenCog Atomese is a lot like JSON, in that one
 can specify arbitrary state structures in JSON.
\end_layout

\begin_layout Standard
There are also some important ways in which atomese differs from JavaScript
 or JSON: atomese allows introspection, i.e.
 it allows for some atoms to control and operate on other atoms, which is
 not possible in JSON.
 Atomese also provides a query language, which JSON does not provide (To
 understand what atomese does, one might imagine writing a SparQL or SQL
 wrapper to query the contents of giant blobs of JSON, or possibly dumping
 large blobs of JSON into Apache Solr or Lucene or Cassandra).
 Atomese also has other language features (it is Prolog-like, it is ML-like)
 that are lacking in Javascript.
 
\end_layout

\begin_layout Standard
Anyway, the goal here is not to debate the design of atomese, but rather
 to indicate that motor-control directives behave more like a language,
 than like an API: thus, it is more correct to think of the system as offering
 a 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

 rather than a 
\begin_inset Quotes eld
\end_inset

control API
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Internal model vs.
 physical body
\end_layout

\begin_layout Standard
The control language needs to control two distinct things: it needs to control
 both the internal model, and also the physical body! That is, a directive
 such as 
\begin_inset Quotes eld
\end_inset

raise the left arm
\begin_inset Quotes erd
\end_inset

 can be used to update the internal model, and it can also be used to control
 the motors on the actual physical body (
\begin_inset Quotes eld
\end_inset

the plant
\begin_inset Quotes erd
\end_inset

, in control-theory terminology).
 There may also be more than one internal model: in control theory, it is
 not uncommon to have a 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "forward model"
target "https://en.wikipedia.org/wiki/Internal_model_(motor_control)#Forward_models"

\end_inset


\begin_inset Quotes erd
\end_inset

, which is used to estimate what might happen if an action was performed,
 or an 
\begin_inset Quotes eld
\end_inset

inverse model
\begin_inset Quotes erd
\end_inset

 as an interface to the physical body.
 Both of these are distinct from the internal model, which models the current
 state, as opposed to some hypothetical future state.
\end_layout

\begin_layout Standard
Other models are possible: this includes memories of past events, where
 some remembered actions might be re-enacted: in this case, the remembered
 actions can be replayed on a remembered model, to reconstruct what happened
 (for example, to answer questions about those events).
 Another possibility is that of predicting the future, where a sequence
 of actions are played out on a model of the hypothetical future, to see
 what might happen.
 In such a case, there might be a model of the audience, as well as a model
 of the self: one is interested in predicting how the audience might react
 to a particular action.
\end_layout

\begin_layout Standard
Rather than inventing a new language for each of these different systems,
 it is convenient to be able to use the same language.
 The under-the-covers implementation is different: in one case, motors must
 be moved; in another case, the model must be updated.
 In either case, the verbs, nouns, adjectives and adverbs should be the
 same.
 (In control theory, this is termed the 
\begin_inset Quotes eld
\end_inset

efference copy
\begin_inset Quotes erd
\end_inset

).
 This is possible as long as the differnt systems use the same underlying
 design scheme: as long as the underlying hypergraphs have the same structure,
 they can be manipulated the same way, never mond that one might represent
 the physical body, and another the self-model.
\end_layout

\begin_layout Subsubsection*
English language interfaces
\end_layout

\begin_layout Standard
Given the above description of the concept of 
\begin_inset Quotes eld
\end_inset

model
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

, one can now imagine that controlling the robot using the English language
 might not be too hard: just translate English to the internal control language,
 and one is done! 
\end_layout

\begin_layout Standard
There is a prototype of this, located in 
\begin_inset CommandInset href
LatexCommand href
name "github"
target "https://github.com/opencog/opencog"

\end_inset

, in the 
\begin_inset CommandInset href
LatexCommand href
name "nlp/chatbot-eva"
target "https://github.com/opencog/opencog/blob/21ad879d85d31013e59870b895bb0a0aef97242c/opencog/nlp/chatbot-eva"

\end_inset

 directory.
 As a prototype, it has issues: these will be discussed later.
 The prototype implements commands for the robot to look in different directions
, and to make different facial expressions.
 This includes imperatives such as 
\begin_inset Quotes eld
\end_inset

look left!
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

pretend you're happy!
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
Control language prototype
\end_layout

\begin_layout Standard
The control language is implemented in 
\begin_inset CommandInset href
LatexCommand href
name "knowledge.scm"
target "https://github.com/opencog/opencog/blob/21ad879d85d31013e59870b895bb0a0aef97242c/opencog/nlp/chatbot-eva/knowledge.scm"

\end_inset

.
 All of the previous discussion is made concrete in this file, and a review
 of this file is strongly recommended.
 This is where the 
\begin_inset Quotes eld
\end_inset

rubber meets the road
\begin_inset Quotes erd
\end_inset

, where things actually happen.
\end_layout

\begin_layout Standard
Lines 80 thru 120 illustrate how spatial directions are grounded in specific
 x,y,z coordinates.
 Lines 127 thru 132 associate specific English-langauge words to these direction
s.
 Lines 135-139 group the control-language direction names into a single
 kind (in this case, into the class 
\begin_inset Quotes eld
\end_inset

schema-direction
\begin_inset Quotes erd
\end_inset

).
 This will be used later, to make sure that the 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 verbs can only take the direction-kind, as opposed to the facial-expression-kin
d.
 This forms the foundation of a crude grammar for the control language:
 it will not be legal to say 
\begin_inset Quotes eld
\end_inset

turn your head to face in the happy direction
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
Lines 145-149 give the two kinds to looking-turning control verbs.
 Lines 166-170 define the control-langauge grammar: the only valid way to
 move the robot head is to specify either the 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 or the 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 verb, followed by a direction-kind.
 (In the current Blender animation subsystem, 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 rotates the entire head (turning the neck) while 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 only moves the eyes.)
\end_layout

\begin_layout Standard
Lines 173-213 duplicate the earlier portion of the file, and implement the
 control language for the internal model (here called the 
\begin_inset Quotes eld
\end_inset

self-model
\begin_inset Quotes erd
\end_inset

, because it is modelling the robot itself).
\end_layout

\begin_layout Standard
Lines 216-306 define the control-adverbs, in one-to-one correspondance to
 the Blender animation names for facial expressions.
 There is exactly *one* control-adverb for each animation: it is not desirable
 to have synonyms in this layer.
 Line 316 defines the one and only control-verb for facial expressions:
 this is the 
\begin_inset Quotes eld
\end_inset

perform a facial animation
\begin_inset Quotes erd
\end_inset

 verb.
\end_layout

\begin_layout Standard
Lines 321-336 associate fifteen different English-language words with this
 one control-verb.
 This is because, in English, synonyms are common and pervasive: it is quite
 natural to say 
\begin_inset Quotes eld
\end_inset

Look happy!
\begin_inset Quotes erd
\end_inset

 
\begin_inset Quotes eld
\end_inset

Act happy!
\begin_inset Quotes erd
\end_inset

 
\begin_inset Quotes eld
\end_inset

Be happy!
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Emote happiness!
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Portray happiness!
\begin_inset Quotes erd
\end_inset

 and mean the same thing.
 Thus, all of these diferent English-language words are mapped to the same
 control-verb.
\end_layout

\begin_layout Standard
Lines 338-511 associate more than one hundred(!) different English-language
 words with the fifteen-or-so different Blender animation names.
 For example, 
\begin_inset Quotes eld
\end_inset

perplexity
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

puzzlement
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

confusion
\begin_inset Quotes erd
\end_inset

 are all valid synonyms for the 
\begin_inset Quotes eld
\end_inset

confused
\begin_inset Quotes erd
\end_inset

 animation.
\end_layout

\begin_layout Standard
Lines 520-531 group together the different Blender facial-exopression animations
 into a single animation-kind.
 
\end_layout

\begin_layout Standard
Lines 534-538 define the control-grammar for performing a facial animation:
 it must necessarily consist of the single perform-facial-animation control-verb
, and one of the fifteen Blender facial-animation adverbs.
 No other compbination is possible: thus one cannot make the control-language
 statement 
\begin_inset Quotes eld
\end_inset

emote leftness
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
These control-grammar rules not only define what it is possible to do with
 the robot, but they also disambiguate certain English-language expressions.
 Very specifically, one can say, in English, 
\begin_inset Quotes eld
\end_inset

Look left!
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Look happy!
\begin_inset Quotes erd
\end_inset

.
 The English-language verb 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 is associated with both the control-language turn-verb (line 199) and also
 the control-language express-verb (line 335).
 Which of these two meanings for the English-language word 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 is intended becomes clear only after the English has been translated into
 conttrol-language.
 The control grammar allows only one, or the other meaning, depending on
 how it is combined with the other control-words.
 In particular, this means that (in this prototype), the control-words are
 always and necessarily unique and unambiguous in thier 
\begin_inset Quotes eld
\end_inset

meaning
\begin_inset Quotes erd
\end_inset

.
 The control words provide 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "grounding"
target "https://en.wikipedia.org/wiki/Symbol_grounding_problem"

\end_inset


\begin_inset Quotes erd
\end_inset

 for meaning.
\end_layout

\begin_layout Standard
Lines 540-560 duplicate the above, but are used for controlling the self-model,
 instead of controlling Blender.
\end_layout

\begin_layout Standard
Lines 570-680 (end of file) repeat the previous structures, but are used
 to control the Blender gesture-animations (blinking, nodding, shaking,
 yawning).
 The very same concepts apply.
 
\end_layout

\begin_layout Subsubsection*
DRAFT VERSION 0.01
\end_layout

\begin_layout Standard
This is a draft.
 Everything above is in some mostly-finished state.
 Everything below is in outline format.
\end_layout

\begin_layout Subsubsection*
Translation prototype
\end_layout

\begin_layout Standard
The prototype includes a module that translates English language to the
 control language.
 Translation consists conceptually of two distinct aspects: mapping the
 syntax of the English language (grammar) to the control-language syntax
 (grammar), and mapping specific English-language words to control-language
 atoms (this second part having already been reviewed above).
\end_layout

\begin_layout Standard
The translation consists of a set of hand-crafted rules that can recognize
 specific kinds of English-langauge sentences, and that convert these into
 the internal-langauge forms.
\end_layout

\begin_layout Standard
There are several technical issues that crop up, at this point.
 One is that the
\end_layout

\begin_layout Standard
issue: learning vs.
 hand-crafting, obtaining synonymous phrases, not just synonymous words.
\end_layout

\begin_layout Standard
issue: using openpsi to discover and apply rules.
 This is like using openpsi in general, to pick through non-verbal stimulus.
\end_layout

\begin_layout Standard
issue: fuzzy matching, partial matching
\end_layout

\begin_layout Standard
issue: picking out sentences attached to an anchor, vs other processing
 pipeline designs.
\end_layout

\begin_layout Subsubsection*
Question-answering
\end_layout

\begin_layout Standard
Answering questions about self and the world.
 Also has been prototyped.
 Its like the 
\begin_inset Quotes eld
\end_inset

view
\begin_inset Quotes erd
\end_inset

 part of MVC -- the internal state has to be 
\begin_inset Quotes eld
\end_inset

viewed
\begin_inset Quotes erd
\end_inset

 easily, in order to be queried.
 Thus, there are a set of 
\begin_inset Quotes eld
\end_inset

standardized state queries
\begin_inset Quotes erd
\end_inset

, analogous to the control language.
 Running these queries returns yes/no answers (truth queries) or multi-valued
 data (e.g.
 look-at direction) or more complex structures (sequences of actions that
 had been performed in the past) 
\end_layout

\begin_layout Standard
There are two translation layers that are needed here: first, to convert
 English to the internal query language, second, to conver the response
 back to English.
 If the response is of the right form, then SuReal can be used to perform
 the final conversion.
 Right now, the query language is not generating SuReal-compatible results.
\end_layout

\begin_layout Subsubsection*
World model
\end_layout

\begin_layout Standard
Right now, there is only a self-model.
 A world-model is needed, so we can talk about that.
 Well --there is a world model -- currently, it consists of the visible
 faces in the environment.
 It needs to get bigger.
\end_layout

\begin_layout Subsubsection*
Action Orchestration
\end_layout

\begin_layout Standard
Carrying out multiple things at once; using the internal model to do this.
\end_layout

\begin_layout Subsubsection*
Memory
\end_layout

\begin_layout Standard
Multiple types of memory are needed.
 Most important (for demo purposes) is memory consisting of imperatives:
 when she is told to do this and say that, she needs to remember this, and
 later on, play that back as a performance.
\end_layout

\begin_layout Standard
This should be 
\begin_inset Quotes eld
\end_inset

straight-forward
\begin_inset Quotes erd
\end_inset

: one can record the control-language directives.
 They need to be marked up with timing information.
\end_layout

\begin_layout Standard
Implementing acting-coaching is interesting, and in particular, implementing
 directives such as 
\begin_inset Quotes eld
\end_inset

do that performance again, except this time, make xyz go more slowly
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
A second type of memory would be remembering past states of the world.
\end_layout

\begin_layout Standard
One techical challenge is that we will need a management layer for the Postgres
 DB interfaces, so that memories are not lost during power-off.
 Those memories need to be segregated: there are somethings that need to
 be rememebered, others that should not be.
\end_layout

\begin_layout Subsubsection*
Free will
\end_layout

\begin_layout Standard
Free will, as defined here, is the over-riding of default behavior (as computed
 by psi-rules) by means of a logically, rationally reasoned course of action.
 For example, the default of the psi rules might be 
\begin_inset Quotes eld
\end_inset

lolly-gag about
\begin_inset Quotes erd
\end_inset

, while a rational decision would be 
\begin_inset Quotes eld
\end_inset

go and do that important thing
\begin_inset Quotes erd
\end_inset

.
 Free wil is then the act of picking between these two alternatives, of
 balancing them out (at a critical phase-transition point).
\end_layout

\begin_layout Section*
Items
\end_layout

\begin_layout Itemize
a person walks into room, who she recognizes.
 Depending on psi, she whould do non-verbal greetings (play one of 3-4 different
 animations (look at, chin push, nod)) and verbal greetings (
\begin_inset Quotes eld
\end_inset

hello, what's up, yo dawg
\begin_inset Quotes erd
\end_inset

).
 split up the state and the psi rule stuff properly.
 See comments here: https://github.com/opencog/ros-behavior-scripting/pull/80
 
\end_layout

\begin_layout Itemize
extract keywords/key-topics from sentence, and remember them, then apply
 fuzzy matcher to see which of these come up.
\end_layout

\begin_layout Section*
Random ideas
\end_layout

\begin_layout Itemize
Why did you smile? Output: have her explain recent opensi decision-making.
\end_layout

\begin_layout Itemize
I'm so sorry about that.
 Output: a small cute pout (blend of frown and ???)
\end_layout

\begin_layout Itemize
Look at me.
 (verify look-at location or report visibility)
\end_layout

\begin_layout Itemize
What are you doing? 
\end_layout

\begin_layout Itemize
(When last person leaves, she should say goodbye.
 If did not say goodbye, then say 
\begin_inset Quotes eld
\end_inset

hey where did everybopdy go?
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Itemize
If no one isvisibile, and no one has been visible for many minutes, she
 should say 
\begin_inset Quotes eld
\end_inset

hey where did everybody go?
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Behavior -- she should not get sleepy, as long as someone is visible.
\end_layout

\begin_layout Itemize
Behavior -- she should complain, if no one is visible, but there is a chat
 session going on.
\end_layout

\end_body
\end_document
